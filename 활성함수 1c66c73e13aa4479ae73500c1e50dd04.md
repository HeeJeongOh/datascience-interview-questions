# 활성함수

# 활성함수

- 실수 공간 위에 정의된 비선형함수
- 활성함수를 쓰지 않으면 선형모형과 차이가 없으므로 활성함수와 선형모델을 합성한 함수가 곧 신경망

활성함수의 종류:

- Sigmoid
- Softmax
- Tanh(hyperbolic tangent)
- ReLU
- LeakyReLU

## Sigmoid

![Untitled](%E1%84%92%E1%85%AA%E1%86%AF%E1%84%89%E1%85%A5%E1%86%BC%E1%84%92%E1%85%A1%E1%86%B7%E1%84%89%E1%85%AE%201c66c73e13aa4479ae73500c1e50dd04/Untitled.png)

**시그모이드 함수:**입력을 0~1 사이의 값으로 바꿔주는 함수

$$
p = \frac{e^{f(x)}}{1+e^{f(x)}} = \frac{1}{1+e^{-{f(x)}}}
$$

### 장점

- **gradient exploding가 발생하지 않는다.**
    - ~~그 이유로는 그래프를 봤을 때 중앙에서 기울기~~

### 단점

- **gradient vanishing**
    - 입력값의 크기에 상관없이 0과 1사이의 값으로 변환하기 때문
- **느린 학습속도**
    - 출력값이 모두 양수이기 때문에 기울기가 음수와 양수 둘 모두를 가지게 된다. 이로 인해 학습이 지그재그 방향으로 진행되기 때문에 속도가 느려진다.

### 활용

출력층에서 이진 분류를 하기 위해 시그모이드를 사용하는 것은 상관없지만, 은닉층에서는 단점으로 인해 시그모이드를 사용하기 어렵다.

## Softmax

$$
y_k = \frac{e^{a_k}}{\sum_{i=1}^{n}e^{a_i}}
$$

**소프트맥스 함수:** 분류할 클래스가 n개일 때, n 차원의 벡터를 입력값으로 받아서 각 클래스에 속할 확률을 추정하는 함수

### 밑을 e로 사용하는 이유

1. 지수함수는 단조 증가 함수이므로 입력값의 대소 관계가 변하지 않는다.
2. 입력값의 차이가 아무리 작아도 출력 결과가 구별될 수 있을 정도로 커진다.
3. 미분을 하기 편하다.

### 활용

- 이진 분류에서 사용하는 시그모이드와 달리 다중 분류를 할 때 출력층에서 사용된다.

## Tanh (hyperbolic tangent)

![Untitled](%E1%84%92%E1%85%AA%E1%86%AF%E1%84%89%E1%85%A5%E1%86%BC%E1%84%92%E1%85%A1%E1%86%B7%E1%84%89%E1%85%AE%201c66c73e13aa4479ae73500c1e50dd04/Untitled%201.png)

**Tanh:** 시그모이드의 단점을 보완한 함수. 

$$
tanhx = \frac{sinhx}{coshx} = \frac{e^x - e^{-x}}{e^x + e^{-x}} 
$$

### 장점

- 시그모이드보다 학습 효율성이 뛰어남
    - 중앙값이 0이기 때문에 기울기가 양수, 음수 모두 나올 수 있다.
- 시그모이드보다 gradient vanishing이 적게 발생한다.
    - 시그모이드보다 출력값의 변화폭이 더 크다.

### 단점

- 그럼에도 기울기 소실은 여전히 발생할 수 있다.

## ReLU

![Untitled](%E1%84%92%E1%85%AA%E1%86%AF%E1%84%89%E1%85%A5%E1%86%BC%E1%84%92%E1%85%A1%E1%86%B7%E1%84%89%E1%85%AE%201c66c73e13aa4479ae73500c1e50dd04/Untitled%202.png)

$$
h(x) = \begin{cases}
 x \ \ \ (x>0) \\ 
 0 \ \ \ (x\leq 0) 
\end{cases}
$$

**ReLU:** 입력값이 음수면 0을 반환하고 양수면 입력값을 그대로 반환하는 함수

## 장점

- gradient vanishing이 발생하지 않는다
    - 양수는 그대로 반환하고 음수는 0으로 반환하기 때문에 특정 양수 값에 수렴하지 않는다.
- 학습 속도가 빠르다
    - 구조가 단순해 다른 활성화 함수에 비해 매우 빠르다.

### 단점

- Dying ReLU
    - 음수 값은 모두 0으로 반환하기 때문에 입력값이 음수일 땐 기울기도 모두 0이 된다. 이 경우엔 가중치 업데이트가 진행되지 않는다.
- 0에서 미분이 불가능하다
    - 실제로 0에 걸릴 확률이 낮기 때문에 무시하고 사용한다.

### 활용

- 은닉층에서만 사용한다.

출처: [https://gooopy.tistory.com/55](https://gooopy.tistory.com/55)